{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKwIVHsxsx__"
   },
   "outputs": [],
   "source": [
    "#pip install keras_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPN9q9THtAx5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Input, Model\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import History, ModelCheckpoint, TensorBoard\n",
    "import numpy as np\n",
    "#import keras_resnet.blocks\n",
    "#import tcn\n",
    "#from tcn import TCN, tcn_full_summary\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "#from tcn import compiled_tcn\n",
    "import os\n",
    "#import keras_resnet.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGERASomu-I8"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phcY5PRevHqi"
   },
   "outputs": [],
   "source": [
    "#with open('/content/drive/My Drive/wavenet-test/features.pickle', 'rb') as handle:\n",
    "#    features = pickle.load(handle)\n",
    "    \n",
    "#with open('/content/drive/My Drive/wavenet-test/labels.pickle', 'rb') as handle:\n",
    "#  labels = pickle.load(handle)\n",
    "\n",
    "#!cp '/content/drive/My Drive/wavenet-test/US8K.tar' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBguM79zyEFq",
    "outputId": "06991a49-2f46-4c86-dea8-d905e0e8bce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  5 20:15:26 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqI7BGbPYWIE"
   },
   "outputs": [],
   "source": [
    "## Utils\n",
    "\n",
    "def create_new_model():\n",
    "  input_shape = (334, 224, 3)\n",
    "\n",
    "  base_model = keras.applications.ResNet50(weights='imagenet',\n",
    "                                           include_top=False,\n",
    "                                           input_shape=input_shape)\n",
    "  # adding regularization\n",
    "  #regularizer = tf.keras.regularizers.l2(0.001)\n",
    "  #for layer in base_model.layers:\n",
    "  #  for attr in ['kernel_regularizer']:\n",
    "  #      if hasattr(layer, attr):\n",
    "  #        setattr(layer, attr, regularizer)\n",
    "  #print(base_model.losses)\n",
    "  #base_model.save_weights('resnet50.h5', save_format='h5')\n",
    "  #base_model = tf.keras.models.model_from_json(base_model.to_json())\n",
    "  # new_model would have random weights\n",
    "  #base_model.load_weights('resnet50.h5')\n",
    "  #print(base_model.losses)\n",
    "  base_model.trainable = False\n",
    "\n",
    " \n",
    "  inputs = keras.Input(shape=input_shape)\n",
    "  # We make sure that the base_model is running in inference mode here,\n",
    "  # by passing `training=False`. This is important for fine-tuning, as you will\n",
    "  # learn in a few paragraphs.\n",
    "  x = base_model(inputs, training=False)\n",
    "  # Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "  # A Dense classifier with a 10 units \n",
    "  outputs = keras.layers.Dense(10)(x)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "  return model\n",
    "\n",
    "\n",
    "def load_model(depth, filters, kernel_size, save_dir=\"./\"):\n",
    "  model = create_new_model(depth, filters, kernel_size)\n",
    "  saved_model = save_dir + \"saved_wavenet_clasifier.h5\"\n",
    "  # model.load here\n",
    "  if os.path.isfile(saved_model):\n",
    "    model.load_weights(saved_model)\n",
    "  else:\n",
    "    print(\"NO MODEL ON DISK, USING BRAND NEW ONE\")\n",
    "  return model\n",
    "\n",
    "def create_callbacks(save_dir=\"./\"):\n",
    "  saved_model = save_dir + \"saved_wavenet_clasifier.h5\"\n",
    "  saved_hist  = save_dir + 'wavenet_classifier_training_history.csv'\n",
    "  checkpointer = ModelCheckpoint(filepath=saved_model, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "  #tensorboard  = TensorBoard(log_dir=save_dir)\n",
    "  history_cb = tf.keras.callbacks.CSVLogger(saved_hist, separator=\",\", append=True)\n",
    "\n",
    "  return [checkpointer, history_cb] # add tensorboard if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhEhWKmnZQ7O",
    "outputId": "a51e96ba-7c73-4d4d-9aaa-b718e43bbc4a"
   },
   "outputs": [],
   "source": [
    "all_X = []\n",
    "all_Y = []\n",
    "fulldatasetpath = './'\n",
    "metadata = pd.read_csv('http://76.213.149.126:8081/metadata/UrbanSound8K.csv')\n",
    "print(metadata)\n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = 'fold'+str(row[\"fold\"])+'/' + str(row[\"slice_file_name\"])\n",
    "    all_X.append(file_name.replace(\".wav\", \"_spec.pkl\"))\n",
    "    all_Y.append(file_name.replace(\".wav\", \"_y2.pkl\"))\n",
    "\n",
    "import requests\n",
    "from multiprocessing.pool import ThreadPool\n",
    " \n",
    "def download_url(url):\n",
    "  #print(\"downloading: \",url)\n",
    "  # assumes that the last segment after the / represents the file name\n",
    "  # if url is abc/xyz/file.txt, the file name will be file.txt\n",
    "  path = url.split(\"/\")\n",
    "  path = path[-2] + \"/\" + path[-1]\n",
    " \n",
    "  r = requests.get(url, stream=True)\n",
    "  if r.status_code == requests.codes.ok:\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "      try:\n",
    "          os.makedirs(os.path.dirname(path))\n",
    "      except OSError as exc: # Guard against race condition\n",
    "          if exc.errno != errno.EEXIST:\n",
    "              raise\n",
    "    with open(path, 'wb') as f:\n",
    "      for data in r:\n",
    "        f.write(data)\n",
    "  return url\n",
    "\n",
    "def set_shapes(x, y):\n",
    "    y.set_shape([4, 10])\n",
    "    x.set_shape([4, 334, 224, 3])\n",
    "    return x, y\n",
    "\n",
    "#from sklearn.model_selection import train_test_split \n",
    "#x_train, x_test, y_train, y_test = train_test_split(all_X, all_Y, test_size=0.2, random_state = 42)\n",
    "\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for x in all_X:\n",
    "  if x[0:5] != \"fold5\":\n",
    "    x_train.append(x)\n",
    "    x_train.append(x.replace(\"_spec.pkl\", \"_augmented_noise_spec.pkl\"))\n",
    "    x_train.append(x.replace(\"_spec.pkl\", \"_augmented_pitch_1_spec.pkl\"))\n",
    "  else:\n",
    "    x_test.append(x)\n",
    "\n",
    "\n",
    "for y in all_Y:\n",
    "  if y[0:5] != \"fold5\":\n",
    "    y_train.append(y)\n",
    "    y_train.append(y)\n",
    "    y_train.append(y)\n",
    "\n",
    "  else:\n",
    "    y_test.append(y)\n",
    "    \n",
    "\n",
    "def file_to_arr(t: tf.Tensor):\n",
    "  x = []\n",
    "  y = []\n",
    "\n",
    "  urls = []\n",
    "\n",
    "  for a in t:\n",
    "    a = np.array(a)\n",
    "    # check whether we have them\n",
    "    # if not, schedule download\n",
    "    if not os.path.exists(a[0]):\n",
    "      urls.append(\"http://76.213.149.126:8081/audio/\" + a[0].decode('UTF-8'))\n",
    "    if not os.path.exists(a[1]):\n",
    "      urls.append(\"http://76.213.149.126:8081/audio/\" + a[1].decode('UTF-8'))\n",
    "  \n",
    "  if (len(urls) > 0):\n",
    "    ThreadPool(4).map(download_url, urls)\n",
    "\n",
    "  for a in t:\n",
    "    a = np.array(a)\n",
    "    #print(a[0])\n",
    "    try:\n",
    "      x.append(pickle.load(open(a[0], 'rb')))\n",
    "      y.append(pickle.load(open(a[1], 'rb')))\n",
    "    except:\n",
    "      os.remove(a[0])\n",
    "      os.remove(a[1])\n",
    "      return file_to_arr(t)\n",
    "\n",
    "  x = np.asarray(x)\n",
    "  x = np.swapaxes(x, 1, 2)\n",
    "  #x = tf.convert_to_tensor(x)\n",
    "  #x.set_shape([341, 513, 2])\n",
    "  x = np.stack([x,x,x], axis=3)\n",
    "  y = np.array(y).astype(int)\n",
    "  res = (x,y)\n",
    "  #print (res)\n",
    "  return (res)\n",
    "\n",
    "print((list(zip(x_train, y_train))))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(list(zip(x_train, y_train)))\n",
    "train_ds = train_ds.shuffle(len(train_ds),seed=42)\n",
    "train_ds = train_ds.batch(4)\n",
    "train_ds = train_ds.map((lambda x: tf.py_function(func=file_to_arr,inp=[x], Tout=(tf.float32, tf.int64))))\n",
    "train_ds = train_ds.map(lambda x, y: set_shapes(x,y) )\n",
    "train_ds = train_ds.prefetch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(list(zip(x_test, y_test)))\n",
    "test_ds = test_ds.batch(4)\n",
    "test_ds = test_ds.map((lambda x: tf.py_function(func=file_to_arr,inp=[x], Tout=(tf.float32, tf.int64))))\n",
    "test_ds = test_ds.map(lambda x, y: set_shapes(x,y) )\n",
    "test_ds = test_ds.prefetch(32)\n",
    "\n",
    "print(test_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUR4vnrGlV49"
   },
   "outputs": [],
   "source": [
    "model = create_new_model()\n",
    "#model = load_model(9, 32, 2, \"./drive/My Drive/wavenet-test/new2/9_32_2_skipconnections_customdropout_run2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFmf6xmbtHjj",
    "outputId": "f9bfff4a-13fe-420f-e92e-8a4d9decf01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 334, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 11, 7, 2048)       23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks = create_callbacks(\"./\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSx_1_XYh8oU"
   },
   "outputs": [],
   "source": [
    "#!mkdir ./checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zxV56ElGt2rK",
    "outputId": "709c1b70-24ce-48b4-a1ed-1b83d3cc89d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5847/5847 [==============================] - ETA: 0s - loss: 8.2603 - accuracy: 0.1046\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.09936, saving model to ./saved_wavenet_clasifier.h5\n",
      "5847/5847 [==============================] - 1588s 272ms/step - loss: 8.2603 - accuracy: 0.1046 - val_loss: 8.9889 - val_accuracy: 0.0994\n",
      "Epoch 2/300\n",
      "5847/5847 [==============================] - ETA: 0s - loss: 8.2603 - accuracy: 0.1046\n",
      "Epoch 00002: val_accuracy did not improve from 0.09936\n",
      "5847/5847 [==============================] - 829s 142ms/step - loss: 8.2603 - accuracy: 0.1046 - val_loss: 8.9889 - val_accuracy: 0.0994\n",
      "Epoch 3/300\n",
      "5847/5847 [==============================] - ETA: 0s - loss: 8.2602 - accuracy: 0.1046\n",
      "Epoch 00003: val_accuracy did not improve from 0.09936\n",
      "5847/5847 [==============================] - 1086s 186ms/step - loss: 8.2602 - accuracy: 0.1046 - val_loss: 8.9889 - val_accuracy: 0.0994\n",
      "Epoch 4/300\n",
      "4512/5847 [======================>.......]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-581d5aaff7cb>\", line 1, in <module>\n",
      "    model.fit(train_ds, validation_data=test_ds, callbacks=callbacks, epochs=300)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1103, in fit\n",
      "    callbacks.on_train_batch_end(end_step, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 440, in on_train_batch_end\n",
      "    self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 289, in _call_batch_hook\n",
      "    self._call_batch_end_hook(mode, batch, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 309, in _call_batch_end_hook\n",
      "    self._call_batch_hook_helper(hook_name, batch, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 342, in _call_batch_hook_helper\n",
      "    hook(batch, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 961, in on_train_batch_end\n",
      "    self._batch_update_progbar(batch, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 1017, in _batch_update_progbar\n",
      "    self.progbar.update(self.seen, list(logs.items()), finalize=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\", line 597, in update\n",
      "    sys.stdout.write(bar)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 400, in write\n",
      "    self.pub_thread.schedule(lambda : self._buffer.write(string))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\", line 203, in schedule\n",
      "    self._event_pipe.send(b'')\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\", line 491, in send\n",
      "    return super(Socket, self).send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 720, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 767, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 242, in zmq.backend.cython.socket._send_copy\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '<ipython-input-12-581d5aaff7cb>'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=test_ds, callbacks=callbacks, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdG-aHgBjOPb"
   },
   "outputs": [],
   "source": [
    "!cat \"./drive/My Drive/wavenet-test/new2/8_32_2_skipconnections_dropout0.1_convkernalsize2/wavenet_classifier_training_history.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXj9Q2lnIV3E"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer, loss=keras.losses.categorical_crossentropy, metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI8W5jDM1Azs"
   },
   "outputs": [],
   "source": [
    "[2 ** i for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BUW2V0VoxNG"
   },
   "outputs": [],
   "source": [
    "t = iter(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5c-fwSkZE149",
    "outputId": "0369596f-f528-4233-8de3-3c869088a8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.16546425e+02, 3.30120125e+01, 2.29048877e-04, ...,\n",
      "        8.28410871e-03, 2.74245769e-01, 5.44586086e+00],\n",
      "       [1.26469215e+02, 3.47922897e+01, 4.51437570e-03, ...,\n",
      "        4.56554741e-02, 3.42672378e-01, 5.46649790e+00],\n",
      "       [1.65045090e+02, 4.54606361e+01, 5.45804501e-01, ...,\n",
      "        2.03821182e-01, 1.48071134e+00, 4.61989307e+00],\n",
      "       ...,\n",
      "       [9.38999653e-02, 4.36816514e-02, 2.26944499e-02, ...,\n",
      "        1.62490236e-03, 1.41818984e-03, 2.08183168e-03],\n",
      "       [8.33851248e-02, 4.29473110e-02, 3.67945954e-02, ...,\n",
      "        1.16338348e-03, 1.06719648e-03, 1.20463257e-03],\n",
      "       [8.52781907e-02, 2.66693570e-02, 3.95554351e-03, ...,\n",
      "        3.45527253e-04, 4.02274105e-04, 2.64959992e-04]], dtype=float32), array([[1.0393705e+01, 2.8661668e+00, 2.4650497e-03, ..., 2.0881442e-03,\n",
      "        7.2612691e-01, 1.4623778e+01],\n",
      "       [1.1885493e+01, 3.4261134e+00, 8.0066798e-03, ..., 5.5891454e-02,\n",
      "        1.0982164e+00, 1.5462135e+01],\n",
      "       [1.3061634e+01, 4.2560687e+00, 5.4517262e-02, ..., 6.7432398e-01,\n",
      "        1.1145214e+00, 1.6290768e+01],\n",
      "       ...,\n",
      "       [9.1259833e-03, 8.9693666e-03, 1.1179682e-02, ..., 1.8892529e-03,\n",
      "        2.9682692e-03, 4.6690637e-03],\n",
      "       [1.0410923e-02, 9.1399327e-03, 7.2254012e-03, ..., 1.4562423e-03,\n",
      "        1.4879773e-03, 2.1524983e-03],\n",
      "       [6.0574906e-03, 3.2155276e-03, 1.5638018e-03, ..., 4.8055968e-04,\n",
      "        5.1868643e-04, 1.2821705e-03]], dtype=float32), array([[9.40597107e+02, 5.15999756e+02, 2.49725403e+02, ...,\n",
      "        1.09601746e+02, 4.80189095e+01, 9.83962173e+01],\n",
      "       [7.44345093e+02, 1.85716843e+02, 6.28030212e+02, ...,\n",
      "        2.06832016e+02, 8.37745743e+01, 5.30926628e+01],\n",
      "       [1.01254962e+03, 1.32289825e+02, 1.01464874e+03, ...,\n",
      "        2.64042938e+02, 9.83742828e+01, 3.81904564e+01],\n",
      "       ...,\n",
      "       [7.32177854e-01, 7.90576279e-01, 6.90884173e-01, ...,\n",
      "        5.52098751e-01, 6.64232552e-01, 4.77514029e-01],\n",
      "       [5.65673590e-01, 7.12749839e-01, 6.50372267e-01, ...,\n",
      "        5.69481790e-01, 4.52764302e-01, 5.97016156e-01],\n",
      "       [6.10856950e-01, 6.74532533e-01, 4.98680174e-01, ...,\n",
      "        7.11319685e-01, 5.70929706e-01, 6.46104038e-01]], dtype=float32), array([[7.52396172e+04, 2.35079062e+04, 8.65613281e+03, ...,\n",
      "        7.30752637e+03, 7.91751172e+03, 2.35968896e+03],\n",
      "       [4.34988906e+04, 1.88861582e+04, 1.34193037e+04, ...,\n",
      "        4.76813428e+03, 3.94061157e+03, 4.17990784e+02],\n",
      "       [6.00749658e+03, 1.46547363e+04, 1.19166357e+04, ...,\n",
      "        1.88342371e+03, 2.71967139e+03, 4.04542114e+02],\n",
      "       ...,\n",
      "       [1.09173469e-02, 8.69087409e-03, 1.26744816e-02, ...,\n",
      "        1.72506161e-02, 1.62252337e-02, 1.83452666e-02],\n",
      "       [1.32143516e-02, 1.31877474e-02, 1.23468935e-02, ...,\n",
      "        9.45048500e-03, 9.22550354e-03, 1.07154120e-02],\n",
      "       [9.30384174e-03, 9.34660155e-03, 1.26074515e-02, ...,\n",
      "        1.08015472e-02, 1.29681369e-02, 1.09919040e-02]], dtype=float32)]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: could not broadcast input array from shape (224,334) into shape (224)\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 242, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 131, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-8-ea5e57082f6d>\", line 92, in file_to_arr\n    x = np.array(x)\n\nValueError: could not broadcast input array from shape (224,334) into shape (224)\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-054e7dd473ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: could not broadcast input array from shape (224,334) into shape (224)\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 242, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 131, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-8-ea5e57082f6d>\", line 92, in file_to_arr\n    x = np.array(x)\n\nValueError: could not broadcast input array from shape (224,334) into shape (224)\n\n\n\t [[{{node EagerPyFunc}}]]"
     ]
    }
   ],
   "source": [
    "g = next(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-e01kM54r_DF"
   },
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "_efzcidn2GlQ",
    "outputId": "0a0417f1-495e-4279-ebc8-ac8e01568b9b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-69bf4dd7aa41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "base_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o35IQQYHBPZG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Attempt 8 22khz ResNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
